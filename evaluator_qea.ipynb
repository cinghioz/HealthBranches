{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "from classes.utils import check_options, extract_option\n",
    "\n",
    "BENCH =  \"/home/cc/PHD/HealthBranches/results/results_QUIZ_bench_\"\n",
    "BASE =  \"/home/cc/PHD/HealthBranches/results/results_QUIZ_baseline_\"\n",
    "MEDQA =  \"/home/cc/PHD/HealthBranches/results-medqa/results_QUIZ_medqa_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_line(df_old, df_new):\n",
    "    # Itera sulle righe del secondo CSV\n",
    "    for _, row in df_new.iterrows():\n",
    "        idx = row[\"ID\"]  # ID nel secondo CSV che corrisponde all'indice del primo CSV\n",
    "        label = row[\"label\"]\n",
    "        \n",
    "        if label == \"1\":\n",
    "            df_old.at[idx, \"correct_option\"] = row[\"correct_option\"]\n",
    "        elif label == \"2\":\n",
    "            df_old.at[idx, \"question\"] = row[\"question\"]\n",
    "\n",
    "    return df_old\n",
    "\n",
    "def evaluate_answers(file_path, model):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # subset_df = pd.read_csv(\"/home/cc/PHD/HealthBranches/question_checked.csv\")\n",
    "\n",
    "    #df = df[~df['question'].isin(subset_df['question'])] # senza le checked\n",
    "    # df = df[df['question'].isin(subset_df['question'])] # solo checked\n",
    "\n",
    "    df['correct_answer'] = df['real']\n",
    "    accs = []\n",
    "\n",
    "    for col in [c for c in df.columns if c.startswith((\"zero_shot\", \"one_shot\"))]:\n",
    "        df[f'{col}_choice'] = df[col].apply(extract_option)\n",
    "        df[f'{col}_is_correct'] = df[f'{col}_choice'] == df['correct_answer']\n",
    "        accuracy = df[f'{col}_is_correct'].mean()\n",
    "        print(f'Accuracy for {col}: {accuracy:.2%}')\n",
    "        accs.append(accuracy)\n",
    "    \n",
    "    accs.insert(0, model)\n",
    "\n",
    "    return accs\n",
    "\n",
    "def evaluate_answers_by_cond(file_path, model, condition_value=None):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Filter the DataFrame for the specific condition if provided.\n",
    "    if condition_value is not None:\n",
    "        df = df[df['name'] == condition_value]\n",
    "    \n",
    "    # Set up the correct answer column.\n",
    "    df['correct_answer'] = df['real']\n",
    "    accs = []\n",
    "\n",
    "    # Loop through each relevant column (those starting with \"zero_shot\" or \"one_shot\").\n",
    "    for col in [c for c in df.columns if c.startswith((\"zero_shot\", \"one_shot\"))]:\n",
    "        df[f'{col}_choice'] = df[col].apply(extract_option)\n",
    "        df[f'{col}_is_correct'] = df[f'{col}_choice'] == df['correct_answer']\n",
    "        accuracy = df[f'{col}_is_correct'].mean()\n",
    "        # print(f'Accuracy for {col} under condition  == {condition_value}: {accuracy:.2%}')\n",
    "        # if accuracy < 0.5:\n",
    "        #      print(f'Accuracy for {col} under condition  == {condition_value}: {accuracy:.2%}')\n",
    "        accs.append(accuracy)\n",
    "    \n",
    "    accs.insert(0, model)\n",
    "    accs.insert(0, condition_value)\n",
    "    return accs\n",
    "\n",
    "def find_incorrect_indices(file_path, model):\n",
    "    df = pd.read_csv(file_path)\n",
    "    subset_df = pd.read_csv(\"/home/cc/PHD/HealthBranches/question_checked.csv\")\n",
    "\n",
    "    #df = df[~df['question'].isin(subset_df['question'])] # senza le checked\n",
    "    # df = df[df['question'].isin(subset_df['question'])] # solo checked\n",
    "    print(f\"dataframe shape: {df.shape}, model: {model}\")\n",
    "\n",
    "    incorrect_indices = df.index[df[\"zero_shot\"].apply(extract_option) != df[\"real\"]].tolist()\n",
    "    return incorrect_indices\n",
    "\n",
    "def find_common_wrongs(lists_of_indices):\n",
    "    if not lists_of_indices:\n",
    "        return []\n",
    "    \n",
    "    # Start with the set of indices from the first list\n",
    "    common = set(lists_of_indices[0])\n",
    "    \n",
    "    # Intersect with the indices from each subsequent list\n",
    "    for indices in lists_of_indices[1:]:\n",
    "        common &= set(indices)\n",
    "    \n",
    "    # Return the sorted list of common indices\n",
    "    return sorted(common)\n",
    "\n",
    "def create_folder_file_dict(root_folder):\n",
    "    folder_dict = {}\n",
    "    # List all items in the root folder\n",
    "    for item in os.listdir(root_folder):\n",
    "        item_path = os.path.join(root_folder, item)\n",
    "        # Check if the item is a directory (folder)\n",
    "        if os.path.isdir(item_path):\n",
    "            # List all files in this subfolder\n",
    "            files = os.listdir(item_path)\n",
    "            # Optionally, filter out directories if needed:\n",
    "            files = [f.lower().split('.')[0] for f in files if os.path.isfile(os.path.join(item_path, f))]\n",
    "            folder_dict[item] = files\n",
    "    return folder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/cc/PHD/HealthBranches/results/results_QUIZ_bench_DeepSeek-R1-Distill-Qwen-7B.csv\")\n",
    "\n",
    "for row in df.iterrows():\n",
    "    if extract_option(df[\"zero_shot_rag\"]) == None:\n",
    "        print(df[\"zero_shot\"])\n",
    "\n",
    "evaluate_answers(BENCH + \"DeepSeek-R1-Distill-Qwen-7B.csv\", \"DeepSeek-R1-Distill-Qwen-7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"mistral:7b\", \"gemma:7b\", \"gemma2:9b\", \"gemma3:4b\", \"llama3.1:8b\", \"qwen2.5:7b\", \n",
    "          \"phi4:14b\", \"llama2:7b\", \"Llama-3.3-70B-Instruct-Turbo-Free\"]\n",
    "bench = [evaluate_answers(f\"{BENCH}{model}.csv\", model) for model in models]\n",
    "baseline = [evaluate_answers(f\"{BASE}{model}.csv\", model) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = pd.read_csv(\"/home/cc/PHD/HealthBranches/results/results_QUIZ_baseline_Llama-3.3-70B-Instruct-Turbo-Free.csv\")['name'].unique().tolist()\n",
    "cats = create_folder_file_dict(\"/home/cc/PHD/HealthBranches/new_trees\")\n",
    "\n",
    "res = []\n",
    "for model in models:\n",
    "    for condition in conditions:\n",
    "        accs = evaluate_answers_by_cond(f\"{BENCH}{model}.csv\", model, condition)\n",
    "        res.append(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_folder = {}\n",
    "for folder, files in cats.items():\n",
    "    for file in files:\n",
    "        file_to_folder[file] = folder\n",
    "\n",
    "# Step 2: Replace the first element in each sublist with the corresponding folder name\n",
    "for sublist in res:\n",
    "    file_name = sublist[0]\n",
    "    if file_name in file_to_folder:\n",
    "        sublist[0] = file_to_folder[file_name]\n",
    "    else:\n",
    "        # Handle the case where the file name is not found in the dictionary\n",
    "        sublist[0] = 'Unknown Folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Aggregate values by category (removing model info)\n",
    "category_values = defaultdict(list)\n",
    "\n",
    "for item in res:\n",
    "    category = item[0].replace(\"trees_\", \"\")  # Remove \"trees_\" prefix\n",
    "    value1 = float(item[2])  # First value column\n",
    "    value2 = float(item[3])  # Second value column\n",
    "    category_values[category].extend([value1])  # Store both values\n",
    "\n",
    "# Compute mean for each category across all models\n",
    "mean_values = {category: np.mean(values) for category, values in category_values.items()}\n",
    "\n",
    "# Step 2: Extract names and mean values for plotting\n",
    "names = list(mean_values.keys())\n",
    "values = list(mean_values.values())\n",
    "\n",
    "# Step 3: Create the horizontal bar chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.barh(names, values, color='skyblue')\n",
    "\n",
    "# Set x-axis limits for proper scaling\n",
    "plt.xlim(0, max(values) + 0.1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, values):\n",
    "    plt.text(value + 0.02, bar.get_y() + bar.get_height()/2, f\"{value:.2f}\", va='center')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Mean Value (All Models)')\n",
    "plt.ylabel('Category')\n",
    "plt.title('Mean Values per Category Across All Models (zero shot)')\n",
    "\n",
    "# Invert y-axis to keep the first item on top\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"mistral:7b\", \"gemma:7b\", \"gemma2:9b\", \"llama3.1:8b\", \"qwen2.5:7b\", \"phi4:14b\"]\n",
    "wrongs = [find_incorrect_indices(f\"{BASE}{model}.csv\", model) for model in models]\n",
    "w2 = [find_incorrect_indices(f\"{BENCH}{model}.csv\", model) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(find_common_wrongs(wrongs+w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{BASE}{\"gemma2:9b\"}.csv\")\n",
    "subset_df = pd.read_csv(\"/home/cc/PHD/HealthBranches/question_checked.csv\")\n",
    "\n",
    "#df = df[~df['question'].isin(subset_df['question'])] # senza le checked\n",
    "df = df[df['question'].isin(subset_df['question'])] # solo checked\n",
    "filtered_df = df.loc[find_common_wrongs(wrongs+w2)]\n",
    "print(f\"filtered_df shape: {filtered_df.shape}\")\n",
    "\n",
    "# Save the filtered dataframe to a CSV file without writing the index column\n",
    "# filtered_df.to_csv(\"/home/cc/PHD/HealthBranches/questions_to_check_BASE.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### BASELINE ###\")\n",
    "for model in models:\n",
    "    print(f\"Results for {model}\")\n",
    "    evaluate_answers(f\"{BASE}{model}.csv\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### BENCH ###\")\n",
    "for model in models:\n",
    "    print(f\"Results for {model}\")\n",
    "    evaluate_answers(f\"{BENCH}{model}.csv\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### MEDQA ###\")\n",
    "for model in models:\n",
    "    print(f\"Results for {model}\")\n",
    "    evaluate_answers(f\"{MEDQA}{model}.csv\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_chart(bench, baseline, bar1, bar2, bar3, xl, yl, title):\n",
    "    # Creiamo un dizionario dalla lista baseline per una ricerca veloce\n",
    "    baseline_dict = {item[0]: item[1] for item in baseline}\n",
    "\n",
    "    # Uniamo le liste\n",
    "    merged_list = [item + [baseline_dict[item[0]]] for item in bench if item[0] in baseline_dict]\n",
    "\n",
    "    # Ordiniamo la lista in base al primo float (item[1])\n",
    "    merged_list.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(merged_list)\n",
    "\n",
    "    # Estrai le etichette e i valori\n",
    "    labels = [x[0] for x in merged_list]\n",
    "    values1 = [x[1] for x in merged_list]\n",
    "    values2 = [x[2] for x in merged_list]\n",
    "    values3 = [x[3] for x in merged_list]\n",
    "\n",
    "    # Imposta la posizione delle barre con più spazio tra i gruppi\n",
    "    x = np.arange(len(labels)) * 1.3  # Moltiplica per aumentare la distanza tra i gruppi\n",
    "    width = 0.35  # Larghezza delle barre\n",
    "\n",
    "    # Aumenta le dimensioni del grafico\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    bars1 = ax.bar(x - width, values1, width, label=bar1)\n",
    "    bars2 = ax.bar(x, values2, width, label=bar2)\n",
    "    bars3 = ax.bar(x + width, values3, width, label=bar3)    \n",
    "\n",
    "    # Etichette e titolo\n",
    "    ax.set_xlabel(xl)\n",
    "    ax.set_ylabel(yl)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "    # Mostra il grafico\n",
    "    plt.show()\n",
    "\n",
    "show_chart(bench, baseline, \"no RAG\", \"RAG\", \"Baseline\", \"Models\", \"Accuracy\", \"Benchmark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import random\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def balance_correct_answer(csv_file, output_file):\n",
    "    # Carica il file CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Definisce le lettere per le opzioni (A, B, C, D, E)\n",
    "    option_letters = list(string.ascii_uppercase[:5])\n",
    "    \n",
    "    # Conta la distribuzione attuale delle risposte corrette\n",
    "    correct_counts = Counter(df['correct_option'])\n",
    "    \n",
    "    # Calcola il numero desiderato per ciascuna lettera\n",
    "    target_count = len(df) // 5\n",
    "    \n",
    "    # Inizializza un dizionario per tenere traccia delle assegnazioni\n",
    "    assigned_counts = {letter: 0 for letter in option_letters}\n",
    "    \n",
    "    # Funzione per ribilanciare la posizione della risposta corretta\n",
    "    def rebalance(row):\n",
    "        options = ast.literal_eval(row['options'].replace(\"['\", '[\"').replace(\"']\", '\"]').replace(\"', '\", '\", \"'))  # Converte la stringa in lista\n",
    "        correct_letter = row['correct_option']\n",
    "        correct_index = option_letters.index(correct_letter)\n",
    "        correct_answer = options[correct_index]\n",
    "        \n",
    "        # Trova le lettere meno usate\n",
    "        available_letters = [letter for letter in option_letters if assigned_counts[letter] < target_count]\n",
    "        \n",
    "        # Se tutte le lettere sono bilanciate, assegna a caso\n",
    "        new_correct_letter = random.choice(available_letters) if available_letters else random.choice(option_letters)\n",
    "        new_correct_index = option_letters.index(new_correct_letter)\n",
    "        \n",
    "        # Rimescola le risposte\n",
    "        random.shuffle(options)\n",
    "        \n",
    "        # Sposta la risposta corretta nella nuova posizione\n",
    "        options.remove(correct_answer)\n",
    "        options.insert(new_correct_index, correct_answer)\n",
    "        \n",
    "        # Aggiorna il conteggio\n",
    "        assigned_counts[new_correct_letter] += 1\n",
    "        \n",
    "        return pd.Series([str(options), new_correct_letter])\n",
    "    \n",
    "    # Applica la funzione a ogni riga\n",
    "    df[['options', 'correct_option']] = df.apply(rebalance, axis=1)\n",
    "    \n",
    "    # Salva il nuovo file CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/home/cc/PHD/HealthBranches/questions_pro/ultimate_questions_v3_full.csv\")\n",
    "print(\"Distribuzione prima:\")\n",
    "print(Counter(df[\"correct_option\"]))\n",
    "\n",
    "# # Esegui la funzione su un file di esempio\n",
    "# bal_df = balance_correct_answer(\"/home/cc/PHD/HealthBranches/questions_pro/ultimate_questions_v3_full.csv\", \"/home/cc/PHD/HealthBranches/questions_pro/ultimate_questions_v3_full_balanced.csv\")\n",
    "\n",
    "# # df = balance_correct_options(df)\n",
    "# print(\"Distribuzione dopo:\")\n",
    "# print(Counter(bal_df[\"correct_option\"]))\n",
    "\n",
    "# df.to_csv(\"/home/cc/PHD/HealthBranches/questions_pro/ultimate_questions_v3_full_balanced.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i CSV\n",
    "df_dataset = pd.read_csv('/home/cc/PHD/HealthBranches/questions_pro/ultimate_questions_v3_full_balanced.csv')       # CSV completo delle domande\n",
    "df_subset = pd.read_csv('/home/cc/PHD/HealthBranches/questions_to_check.csv')         # CSV con le domande da correggere\n",
    "df_corrected = pd.read_csv('/home/cc/PHD/HealthBranches/question_checked.csv')    # CSV con le domande corrette; contiene la colonna \"ID\" (l'indice nel CSV subset)\n",
    "\n",
    "# Resetta l'indice di df_subset per garantire che sia numerato da 0 a len(df_subset)-1\n",
    "# df_subset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mapping = {}\n",
    "for _, row in df_corrected.iterrows():\n",
    "    idx = int(row['ID'])\n",
    "    if idx < len(df_subset):\n",
    "        original_question = df_subset.loc[idx, 'question']\n",
    "        mapping[original_question] = {\n",
    "            'question': row['question'],\n",
    "            'answer': row['answer'],\n",
    "            'options': row['options'],\n",
    "            'correct_option': row['correct_option'],\n",
    "            'path': row['path']\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Warning: ID {idx} non presente in df_subset\")\n",
    "\n",
    "# Funzione per aggiornare una riga del dataset, se la domanda è presente nel mapping\n",
    "def update_row(row):\n",
    "    corrections = mapping.get(row['question'])\n",
    "    if corrections:\n",
    "        row['question'] = corrections['question']\n",
    "        row['answer'] = corrections['answer']\n",
    "        row['options'] = corrections['options']\n",
    "        row['correct_option'] = corrections['correct_option']\n",
    "        row['path'] = corrections['path']\n",
    "    return row\n",
    "\n",
    "# Applica la funzione a ogni riga del dataset\n",
    "df_dataset = df_dataset.apply(update_row, axis=1)\n",
    "df_dataset.drop(columns=['answer'], inplace=True)\n",
    "\n",
    "# Salva il dataset aggiornato\n",
    "df_dataset.to_csv('dataset_updated.csv', index=False)\n",
    "print(\"Dataset aggiornato salvato come 'dataset_updated.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
