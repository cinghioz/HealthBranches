{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_paths(main_csv, folder_path):\n",
    "    # Carica il CSV principale\n",
    "    main_df = pd.read_csv(main_csv)\n",
    "    main_paths = set(main_df['path'].dropna().astype(str))  # Rimuove i NaN e converte in stringa\n",
    "    \n",
    "    # Itera su tutti i CSV nella cartella\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"Error: {file} empty, skip.\")\n",
    "                continue\n",
    "\n",
    "            if 'paths' in df.columns:\n",
    "                # Rimuove le sotto-stringhe presenti in main_paths\n",
    "                df['paths'] = df['paths'].astype(str).apply(lambda x: '||'.join([p for p in x.split('||') if p not in main_paths]))\n",
    "                df = df[df['paths'] != '']\n",
    "\n",
    "                new_path = os.path.join(\"/home/cc/PHD/ragkg/last_paths\", file)\n",
    "                # Salva il file aggiornato\n",
    "                df.to_csv(new_path, index=False)\n",
    "                # print(f\"File aggiornato: {file}\")\n",
    "\n",
    "def count_remaining_paths(folder_path):\n",
    "    total_paths = 0\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                if 'paths' in df.columns:\n",
    "                    total_paths += sum(len(str(p).split('||')) for p in df['paths'].dropna())\n",
    "            except pd.errors.EmptyDataError:\n",
    "                continue\n",
    "    print(f\"Totale path rimanenti nei CSV aggiornati: {total_paths}\")\n",
    "\n",
    "# Esegui la funzione\n",
    "filter_paths('/home/cc/PHD/ragkg/questions_pro/ultimate_questions_v2.csv', '/home/cc/PHD/ragkg/paths')\n",
    "count_remaining_paths('/home/cc/PHD/ragkg/last_paths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_inference(model, path, text, cond):\n",
    "    query = f\"The reasoning sequence is as follows: \\\"{path}\\\", the context associated is: \\\"{text}\\\" and the symptom/condition to be treated is: \\\"{cond}\\\".\"\n",
    "    lock = False\n",
    "\n",
    "    while not lock:\n",
    "        time.sleep(7)\n",
    "        chat_session = model.start_chat(history=[])\n",
    "        response = chat_session.send_message(query)\n",
    "        to_list = ast.literal_eval(response.text)\n",
    "        lock = parse_output(to_list)\n",
    "\n",
    "    to_list.append(path)\n",
    "    to_list.append(cond)\n",
    "\n",
    "    return to_list\n",
    "\n",
    "def parse_output(question_data):\n",
    "    if not isinstance(question_data, list) or len(question_data) != 4:\n",
    "        print(\"The main list must have exactly four elements.\")\n",
    "        return False\n",
    "\n",
    "    question, answer, options, correct_option = question_data\n",
    "\n",
    "    if not isinstance(question, str) or not isinstance(answer, str):\n",
    "        print(\"The main list must have exactly four elements.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        options = options.replace(\"['\", '[\"').replace(\"']\", '\"]').replace(\"', '\", '\", \"')\n",
    "        options = ast.literal_eval(options)\n",
    "    except (SyntaxError, ValueError):\n",
    "        print(\"The third element must be a valid list in string format.\")\n",
    "        return False\n",
    "\n",
    "    if not isinstance(options, list) or len(options) != 5 or not all(isinstance(opt, str) for opt in options):\n",
    "        print(\"The options list must contain exactly five string elements.\")\n",
    "        return False\n",
    "\n",
    "    if not isinstance(correct_option, str) or len(correct_option) != 1 or correct_option not in \"ABCDEabcde\":\n",
    "        print(\"The correct option must be a single letter (A-E)\")\n",
    "        return False\n",
    "    \n",
    "    if (answer.lower() not in options[ord(correct_option.upper()) - 65].lower()) or (options[ord(correct_option.upper()) - 65].lower() not in answer.lower()):\n",
    "        print(\"The correct option must be present in the answer.\")   \n",
    "        # print(f\"Correct option: {options[ord(correct_option.upper()) - 65].lower()}\\n\")\n",
    "        # print(f\"Answer: {answer.lower()}\\n\")     \n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key='AIzaSyD_aI_M2ysuA1AhhQI-WoaTlMMOm0njqbk')\n",
    "# genai.configure(api_key=\"AIzaSyC-xkk_sjuGdLOTc-MvrjBI4Bdww5ubo4s\") # matr\n",
    "#Â genai.configure(api_key=\"AIzaSyAOTNKpnJtD5XVjipFAaEYjxm-ZkYEa_74\") # pucci\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8196,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  # model_name=\"gemini-2.0-pro-exp-02-05\",\n",
    "  model_name=\"gemini-2.0-flash\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction='''Given a sequence of reasoning and a text related to it about how to treat a symptom/condition, generate:\\n\\n\n",
    "                        1. a question reflecting the reasoning of the sequence provided. The question must also include a clinical case, e.g: \"A 67-year-old man is brought to the physician \n",
    "                          because of increasing forgetfulness, unsteadiness, and falls over the past year...\"\\n\n",
    "                        2. A set of 5 possible answers (A,B,C,D,E). Should not be too long and should also reflect the sequence of reasoning. One of them must be the correct answer. \n",
    "                          The other answers need not be correct for the generated question but must be related to the topic of the question.\\n\\n \n",
    "                        The sequence does NOT have to be explicit in both question and answers!\\n\\n\n",
    "                        The correct option must be the same as the answer.\\n\\n\n",
    "                        The output should be structured in the following format:\\n\n",
    "                        [\"question\", \"answer\", \"['Option A', 'Option B', 'Option C', 'Option D', 'Option E']\", \"letter of correct option\"]\\n\\n\n",
    "                        Do not generate any additional texts.\\n\\n\n",
    "                        '''\n",
    ")\n",
    "\n",
    "path_folder_name = '/home/cc/PHD/ragkg/last_paths/'\n",
    "txt_folder_name = \"/home/cc/PHD/ragkg/data/kgbase-new/\"\n",
    "csv_paths = os.listdir(path_folder_name)\n",
    "\n",
    "ultimate_questions_path = \"/home/cc/PHD/ragkg/questions_pro/ultimate_questions_v2_part2.csv\"\n",
    "\n",
    "# Load ultimate_questions CSV\n",
    "try:\n",
    "    ultimate_questions = pd.read_csv(ultimate_questions_path, sep=\",\", encoding='utf-8')\n",
    "    processed_conditions = set(ultimate_questions[\"condition\"].astype(str).unique())\n",
    "except FileNotFoundError:\n",
    "    ultimate_questions = pd.DataFrame(columns=['question', 'answer', 'options', 'correct_option', 'path', 'condition'])\n",
    "    processed_conditions = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique \"cond\" values from csv_paths\n",
    "csv_names = {csv.split(\".\")[0].lower() for csv in csv_paths}\n",
    "\n",
    "# Filter out already processed CSVs\n",
    "csvs_to_process = [csv for csv in csv_paths if csv.split(\".\")[0].lower() not in processed_conditions]\n",
    "\n",
    "qeas = []\n",
    "\n",
    "print(f\"Remaining CSVs to process: {len(csvs_to_process)}\")\n",
    "for csv in csvs_to_process:\n",
    "    try:\n",
    "        paths = pd.read_csv(os.path.join(path_folder_name, csv), sep=\",\")\n",
    "    except Exception:\n",
    "        print(f\"{csv} path is EMPTY!\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join(txt_folder_name, csv.replace(\"csv\", \"txt\")), 'r') as file:\n",
    "            text = file.readlines()\n",
    "    except Exception:\n",
    "        print(os.path.join(txt_folder_name, csv))\n",
    "        print(f\"{csv} text is EMPTY!\")\n",
    "        continue\n",
    "\n",
    "    cond = csv.split(\".\")[0].lower()\n",
    "    \n",
    "    for _, row in paths.iterrows():\n",
    "        try:\n",
    "            if '||' in row['paths']:\n",
    "                sub_paths = row['paths'].split('||')\n",
    "                qeas.extend([gemini_inference(model, path, text, cond) for path in sub_paths])\n",
    "            else:\n",
    "                qeas.append(gemini_inference(model, row['paths'], text, cond))\n",
    "        except Exception:\n",
    "            print(\"MODEL IN ERROR, SKIP ROW...\")\n",
    "            continue\n",
    "\n",
    "    # Create DataFrame and append new rows\n",
    "    new_df = pd.DataFrame(qeas, columns=['question', 'answer', 'options', 'correct_option', 'path', 'condition'])\n",
    "    updated_df = pd.concat([ultimate_questions, new_df], ignore_index=True)\n",
    "\n",
    "    # Save updated CSV\n",
    "    updated_df.to_csv(ultimate_questions_path, index=False, encoding='utf-8')\n",
    "\n",
    "    print(f\"{csv} processed!\")\n",
    "\n",
    "print(\"END!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/cc/PHD/ragkg/questions_pro/ultimate_questions_v2_part2.csv\")\n",
    "\n",
    "# Get lengths of strings\n",
    "lengths = [len(s) for s in df['answer'].values]\n",
    "\n",
    "# Calculate max, min, and mean length\n",
    "max_length = max(lengths)\n",
    "min_length = min(lengths)\n",
    "mean_length = np.mean(lengths)  # Using numpy for mean calculation\n",
    "\n",
    "print(f\"Max Length: {max_length}\")\n",
    "print(f\"Min Length: {min_length}\")\n",
    "print(f\"Mean Length: {mean_length:.2f}\")  # Rounded to 2 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Define regex patterns for each rule\n",
    "pattern1 = r\"^\\([abcde]\\) \"         # Rule 1: Start with a, b, c, d, e followed by a space\n",
    "pattern2 = r\"^[abcde]\\.\"        # Rule 2: Start with a, b, c, d, e followed by a dot\n",
    "# pattern3 = r\"^\\([abcde]\\)|\\)[abcde]\"  # Rule 3: Start with (a), (b), (c), (d), (e) or single ')'\n",
    "# pattern4 = r\"\\([^)]*[abcde][^)]*\\)\"   # Rule 4: Contain a, b, c, d, e inside parentheses\n",
    "\n",
    "# Filter strings based on the patterns\n",
    "filtered_strings = [\n",
    "    s for s in df['answer'].values if re.match(pattern1, s.lower()) or \n",
    "                          re.match(pattern2, s.lower()) \n",
    "]\n",
    "\n",
    "# Print results\n",
    "filtered_strings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
