{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61cbe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4657f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_inference(model, chat_session, path, cond, text):\n",
    "    query = f\"The reasoning sequence is as follows: \\\"{path}\\\", the context associated is: \\\"{text}\\\" \\\n",
    "                and the symptom/condition to be treated is: \\\"{cond}\\\".\"\n",
    "\n",
    "    lock = True\n",
    "\n",
    "    while lock:\n",
    "        time.sleep(3)\n",
    "        # chat_session = model.start_chat(history=[])\n",
    "        response = chat_session.send_message(query)\n",
    "        if len(response.text.split('->')) > 1:\n",
    "            lock = False\n",
    "\n",
    "    return response.text\n",
    "\n",
    "genai.configure(api_key='AIzaSyD_aI_M2ysuA1AhhQI-WoaTlMMOm0njqbk')\n",
    "# genai.configure(api_key=\"AIzaSyC-xkk_sjuGdLOTc-MvrjBI4Bdww5ubo4s\") # matr\n",
    "#Â genai.configure(api_key=\"AIzaSyAOTNKpnJtD5XVjipFAaEYjxm-ZkYEa_74\") # pucci\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8196,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  # model_name=\"gemini-2.0-pro-exp-02-05\",\n",
    "  model_name=\"gemini-2.0-flash\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction='''Given a sequence of reasoning and associated context, you have to refine it so \n",
    "                        that it is uniform with medical terminology. The context is a sequence of sentences that can \n",
    "                        be used to clarify the reasoning.\\n\n",
    "                        The meaning of the sequence must NOT change (at most, you can remove superfluous information). \n",
    "                        If the reasoning step is poorly explained or ambiguous, refine it using the context and your medical knowledge.\\n\n",
    "                        The answer must be a sequence of reasoning with -> indicating the transition between one step and the next. \n",
    "                        Do not add any more text or reasoning in your answer, just the sequence.\\n\n",
    "                        '''\n",
    ")\n",
    "\n",
    "chat_session = model.start_chat(history=[])\n",
    "\n",
    "txt_folder_name = \"/Users/cinghio/Documents/PHD/HealthBranches/data/kgbase\"\n",
    "dataset = pd.read_csv(\"/Users/cinghio/Documents/PHD/HealthBranches/questions_pro/dataset_updated.csv\", sep=\",\", encoding='utf-8')\n",
    "\n",
    "csv_path = \"/Users/cinghio/Documents/PHD/HealthBranches/refined_paths.csv\"\n",
    "start_index = -1  \n",
    "\n",
    "if os.path.exists(csv_path):\n",
    "    new_paths = pd.read_csv(csv_path, sep=\",\", encoding='utf-8')\n",
    "\n",
    "    if not new_paths.empty:\n",
    "        start_index = new_paths.tail(1)[\"index\"].values[0]\n",
    "    print(\"CSV loaded successfully.\")\n",
    "else:\n",
    "    new_paths = pd.DataFrame()\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop through the dataset (here limiting to the first 15 rows as example)\n",
    "for index, data in dataset[:15].iterrows():\n",
    "\n",
    "    if index <= start_index:\n",
    "        continue\n",
    "\n",
    "    condition = data['condition']\n",
    "    print(condition.upper())\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join(txt_folder_name, condition.upper() + '.txt'), 'r') as file:\n",
    "            text = file.readlines()\n",
    "    except Exception:\n",
    "        print(f\"{condition.upper()} text is EMPTY!\")\n",
    "        continue\n",
    "    \n",
    "    output = gemini_inference(model, chat_session, data['path'], condition, text)\n",
    "\n",
    "    print(f\"Initial path: {data['path']}\")\n",
    "    print(f\"Processed path: {output}\")\n",
    "\n",
    "    # Append current iteration result to the list\n",
    "    results.append({\n",
    "        'index': index,\n",
    "        'old_path': data['path'],\n",
    "        'new_path': output,\n",
    "        'condition': condition\n",
    "    })\n",
    "    \n",
    "    # Every 5 iterations, merge new results with existing CSV and save\n",
    "    if index % 50 == 0:\n",
    "        combined = pd.concat([new_paths, pd.DataFrame(results)], ignore_index=True)\n",
    "        combined.to_csv(csv_path, index=False)\n",
    "        print(f\"Saved CSV file: {csv_path}\")\n",
    "\n",
    "        new_paths = combined.copy()\n",
    "        results = [] \n",
    "\n",
    "# If there are any remaining results not saved (if not on a 5-iteration boundary)\n",
    "if results:\n",
    "    combined = pd.concat([new_paths, pd.DataFrame(results)], ignore_index=True)\n",
    "    combined.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved final CSV file: {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
