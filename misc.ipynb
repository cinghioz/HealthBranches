{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import ast\n",
    "from together import Together\n",
    "from alive_progress import alive_bar\n",
    "from collections import Counter\n",
    "\n",
    "from prompt import *\n",
    "from classes.utils import extract_option\n",
    "\n",
    "PATH = \"/home/cc/PHD/HealthBranches/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/cc/PHD/HealthBranches/questions_pro/dataset_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for c in df['correct_option'].values:\n",
    "    if c not in [\"A\", \"B\", \"C\", \"D\", \"E\"]:\n",
    "        print(i)\n",
    "        print(df.loc[i]['correct_option'])\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{PATH}results/results_quiz_Llama-3.3-70B-Instruct-Turbo-Free.csv\")\n",
    "df[\"zero_shot_new\"] = df[\"zero_shot\"].apply(extract_option)\n",
    "\n",
    "big_filtered = df[df[\"zero_shot_new\"].str.upper() != df[\"real\"].str.upper()]\n",
    "len(big_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = pd.read_csv(f\"{PATH}results/results_quiz_mistral.csv\")\n",
    "small_df = small_df[small_df[\"question\"].isin(big_filtered[\"question\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df[\"zero_shot_new\"] = small_df[\"zero_shot\"].apply(extract_option)\n",
    "small_filtered = small_df[small_df[\"zero_shot_new\"].str.upper() != small_df[\"real\"].str.upper()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory contenente i file CSV\n",
    "csv_directory = \"/home/cc/PHD/HealthBranches/quiz-ultimate-dataset\"\n",
    "\n",
    "# Leggere tutti i CSV\n",
    "csv_files = [os.path.join(csv_directory, f) for f in os.listdir(csv_directory) if f.endswith(\".csv\")]\n",
    "questions = []\n",
    "\n",
    "print(csv_files)\n",
    "\n",
    "# Elaborazione di ogni CSV\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Rimuove la colonna \"zero_shot_rag\" se esiste\n",
    "    if \"zero_shot_rag\" in df.columns:\n",
    "        df = df.drop(columns=[\"zero_shot_rag\"])\n",
    "\n",
    "    # Applica la funzione di estrazione su zero_shot\n",
    "    df[\"zero_shot\"] = df[\"zero_shot\"].apply(extract_option)\n",
    "\n",
    "    # Filtra le righe in cui zero_shot è diverso da real\n",
    "    df_filtered = df[df[\"zero_shot\"] != df[\"real\"]].copy()\n",
    "\n",
    "    questions.extend(df_filtered['question'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta le occorrenze\n",
    "conteggio = Counter(questions)\n",
    "\n",
    "# Ordina in ordine decrescente\n",
    "dizionario_ordinato = dict(sorted(conteggio.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "filtered_dict = {k: v for k, v in dizionario_ordinato.items() if v >= 6}\n",
    "\n",
    "print(len(filtered_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_to_check = pd.read_csv(\"/home/cc/PHD/HealthBranches/questions_to_check.csv\")\n",
    "\n",
    "# Trova le domande che sono sia nel dizionario che nel DataFrame\n",
    "matching_questions = [q for q in filtered_dict.keys() if q in questions_to_check[\"question\"].values]\n",
    "print(len(matching_questions))\n",
    "\n",
    "print(\"Domande trovate nel DataFrame:\", len(matching_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il CSV (sostituisci 'file.csv' con il tuo file)\n",
    "df = pd.read_csv(\"/home/cc/PHD/HealthBranches/results/results_checker_70B.csv\")\n",
    "\n",
    "# Conta le occorrenze di ogni valore nella colonna \"check\"\n",
    "conteggio = df[\"check\"].value_counts().sort_index()\n",
    "\n",
    "# Stampa il risultato\n",
    "print(conteggio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from typing import List\n",
    "\n",
    "class LLMinference:\n",
    "    def __init__(self, llm_name, temperature=0.0, num_predict=128):\n",
    "        self.llm_name = llm_name\n",
    "        self.model = OllamaLLM(model=llm_name, temperature=temperature, num_predict=num_predict,\n",
    "                               system=\"Answer the question directly without including any reasoning or explanation. Do not use <think> tags or any analytical text.\") \n",
    "\n",
    "    def _transform_query(self, query: str) -> str:\n",
    "        return f'Represent this sentence for searching relevant passages: {query}'\n",
    "\n",
    "    def single_inference(self, query: str, template: str, path: str, text: str,  choices: List[str], cond: str,  context) -> str | List[str]:\n",
    "        context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in context])\n",
    "        prompt_template = ChatPromptTemplate.from_template(template)\n",
    "        \n",
    "        if choices: # quiz\n",
    "            if path != \"\" and text != \"\":\n",
    "                prompt = prompt_template.format(context=context_text, question=query, path=path, text=text, condition=cond, o1=choices[0], o2=choices[1], o3=choices[2], o4=choices[3], o5=choices[4])\n",
    "            else:\n",
    "                prompt = prompt_template.format(context=context_text, question=query, condition=cond, o1=choices[0], o2=choices[1], o3=choices[2], o4=choices[3], o5=choices[4])\n",
    "        else: # open question\n",
    "            if path != \"\" and text != \"\":\n",
    "                prompt = prompt_template.format(context=context_text, question=query, path=path, text=text, condition=cond)\n",
    "            else:\n",
    "                prompt = prompt_template.format(context=context_text, question=query, condition=cond)\n",
    "\n",
    "        response_text = self.model.invoke(prompt)\n",
    "        response_text = response_text.strip().replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "        sources = [doc.metadata.get(\"source\", None) for doc in context]\n",
    "        \n",
    "        return response_text, sources\n",
    "\n",
    "    def qea_evaluation(self, query: str, template: str, path: str, txt: str, choices: List[str], cond: str, vector_store, k: int = 3) -> str:\n",
    "\n",
    "        results = vector_store.search(query=query, k=3)\n",
    "\n",
    "        response, sources = self.single_inference(query, template, path, txt, choices, cond, results)\n",
    "\n",
    "        return response\n",
    "\n",
    "    def inf(self, string):\n",
    "        response_text = self.model.invoke(string)\n",
    "        return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep = LLMinference(\"deepseek-r1:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep.inf(\"Question: what is the capital of germany? \\n Answer: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esecuzione su: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d918c129da4e81bba376e56e7d5095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di righe in cui almeno un segmento del path risulta simile (>= 80%) all'opzione corretta: 839\n",
      "      index                                           question  \\\n",
      "0         0  A 72-year-old male presents with symptoms of P...   \n",
      "1         1  A 70-year-old patient presents with resting tr...   \n",
      "2         2  A 68-year-old male presents with a resting tre...   \n",
      "3         4  A 72-year-old patient presents with resting tr...   \n",
      "4         5  A 68-year-old male presents with a resting tre...   \n",
      "...     ...                                                ...   \n",
      "4105   4109  A 55-year-old male presents with difficulty sw...   \n",
      "4106   4110  A 58-year-old male presents with difficulty sw...   \n",
      "4107   4111  A 55-year-old male presents to your office com...   \n",
      "4108   4112  A 55-year-old male presents with a year-long h...   \n",
      "4109   4113  A 52-year-old male with a history of bipolar d...   \n",
      "\n",
      "                                                options correct_option  \\\n",
      "0     ['Start a dopamine agonist such as pramipexole...              B   \n",
      "1     ['Progressive supranuclear palsy', 'Multiple s...              D   \n",
      "2     ['Amantadine', 'Entacapone', 'Trihexyphenidyl'...              E   \n",
      "3     ['Prescribe an anticholinergic medication to m...              E   \n",
      "4     ['Refer the patient for deep brain stimulation...              E   \n",
      "...                                                 ...            ...   \n",
      "4105  ['Prescribe a trial of corticosteroids', 'Inve...              B   \n",
      "4106  ['Recommend a gluten-free diet', 'Perform esop...              B   \n",
      "4107  ['Initiate a trial of proton pump inhibitors (...              D   \n",
      "4108  ['Recommend a repeat barium swallow with a mar...              B   \n",
      "4109  ['Dehydration', 'Diabetes insipidus', 'Primary...              B   \n",
      "\n",
      "                                               old_path  \\\n",
      "0     History, Physical examination -> Drug-induced ...   \n",
      "1     History, Physical examination -> Give Levodopa...   \n",
      "2     History, Physical examination -> Give Levodopa...   \n",
      "3     History, Physical examination -> Give Levodopa...   \n",
      "4     History, Physical examination -> Give Levodopa...   \n",
      "...                                                 ...   \n",
      "4105  Patient presents with difficulty swallowing ->...   \n",
      "4106  Patient with dysphagia -> Detailed history and...   \n",
      "4107  Patient presents with difficulty swallowing ->...   \n",
      "4108  Patient presents with difficulty swallowing ->...   \n",
      "4109  Determine plasma osmolality -> Measure urine N...   \n",
      "\n",
      "                                                   path            condition  \\\n",
      "0     History and physical examination suggestive of...  parkinson’s disease   \n",
      "1     History, physical examination -> Levodopa tria...  parkinson’s disease   \n",
      "2     History, physical examination -> Levodopa tria...  parkinson’s disease   \n",
      "3     History, physical examination -> Levodopa tria...  parkinson’s disease   \n",
      "4     History, physical examination -> Levodopa tria...  parkinson’s disease   \n",
      "...                                                 ...                  ...   \n",
      "4105  Patient presents with dysphagia -> Initial ass...            dysphagia   \n",
      "4106  Patient with dysphagia -> Detailed history and...            dysphagia   \n",
      "4107  Patient presents with dysphagia -> Initial ass...            dysphagia   \n",
      "4108  Patient presents with dysphagia -> Initial ass...            dysphagia   \n",
      "4109  Evaluate for hypernatremia -> Determine plasma...        hypernatremia   \n",
      "\n",
      "                                          path_segments  \\\n",
      "0     [History and physical examination suggestive o...   \n",
      "1     [History, physical examination, Levodopa trial...   \n",
      "2     [History, physical examination, Levodopa trial...   \n",
      "3     [History, physical examination, Levodopa trial...   \n",
      "4     [History, physical examination, Levodopa trial...   \n",
      "...                                                 ...   \n",
      "4105  [Patient presents with dysphagia, Initial asse...   \n",
      "4106  [Patient with dysphagia, Detailed history and ...   \n",
      "4107  [Patient presents with dysphagia, Initial asse...   \n",
      "4108  [Patient presents with dysphagia, Initial asse...   \n",
      "4109  [Evaluate for hypernatremia, Determine plasma ...   \n",
      "\n",
      "                                    correct_option_text  is_similar_in_path  \n",
      "0     Discontinue metoclopramide and assess for symp...               False  \n",
      "1                            Striatonigral degeneration               False  \n",
      "2                                            Selegiline               False  \n",
      "3     Initiate treatment with Levodopa/Carbidopa and...               False  \n",
      "4     Initiate treatment with a dopamine agonist to ...               False  \n",
      "...                                                 ...                 ...  \n",
      "4105               Investigate other motility disorders                True  \n",
      "4106                       Perform esophageal manometry               False  \n",
      "4107  Perform esophageal manometry to evaluate for m...               False  \n",
      "4108  Initiate treatment for achalasia, such as pneu...               False  \n",
      "4109                                 Diabetes insipidus               False  \n",
      "\n",
      "[4110 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Se la GPU è disponibile, usa 'cuda', altrimenti 'cpu'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Esecuzione su: {device}\")\n",
    "\n",
    "# Carica il modello sulla GPU se disponibile\n",
    "model = SentenceTransformer('all-mpnet-base-v2', device=device)\n",
    "\n",
    "# Sostituisci 'data.csv' con il percorso del tuo file CSV.\n",
    "df = pd.read_csv('/home/cc/PHD/HealthBranches/questions_pro/dataset_updated_V2path.csv')\n",
    "\n",
    "# Definisce la soglia di similarità (80%)\n",
    "SIMILARITY_THRESHOLD = 0.9\n",
    "\n",
    "# Pre-elabora il DataFrame:\n",
    "# 1. Dividi il campo 'path' in una lista di segmenti\n",
    "df['path_segments'] = df['path'].apply(lambda x: [seg.strip() for seg in x.split(\"->\")])\n",
    "# 2. Estrai il testo dell'opzione corretta\n",
    "def extract_correct_option(row):\n",
    "    try:\n",
    "        options_list = ast.literal_eval(row['options'].replace(\"['\", '[\"').replace(\"']\", '\"]').replace(\"', '\", '\", \"'))\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        # Se il parsing fallisce, restituisce una stringa vuota\n",
    "        return \"\"\n",
    "    correct_letter = row['correct_option'].strip().upper()\n",
    "    index = ord(correct_letter) - ord('A')\n",
    "    if index < 0 or index >= len(options_list):\n",
    "        return \"\"\n",
    "    return options_list[index]\n",
    "\n",
    "df['correct_option_text'] = df.apply(extract_correct_option, axis=1)\n",
    "\n",
    "# Elabora in batch gli embedding delle opzioni corrette\n",
    "correct_texts = df['correct_option_text'].tolist()\n",
    "correct_embeddings = model.encode(correct_texts, device=device, convert_to_tensor=True)\n",
    "\n",
    "# Funzione per verificare in una riga se almeno un segmento del path è semanticamente simile all'opzione corretta\n",
    "def check_similar_option_batch(idx, row):\n",
    "    segments = row['path_segments']\n",
    "    # Se non ci sono segmenti, ritorna False\n",
    "    if not segments:\n",
    "        return False\n",
    "    # Calcola in batch gli embedding dei segmenti (convert_to_tensor=True per operare su GPU)\n",
    "    segments_embeddings = model.encode(segments, device=device, convert_to_tensor=True)\n",
    "    # Recupera l'embedding dell'opzione corretta per la riga corrente\n",
    "    correct_emb = correct_embeddings[idx]\n",
    "    # Normalizza gli embedding per applicare correttamente il calcolo della similarità coseno\n",
    "    correct_norm = correct_emb / correct_emb.norm()\n",
    "    segments_norm = segments_embeddings / segments_embeddings.norm(dim=1, keepdim=True)\n",
    "    # Calcola la similarità coseno tra l'opzione e ogni segmento\n",
    "    similarities = torch.matmul(segments_norm, correct_norm)\n",
    "    # Se almeno una similarità supera la soglia, ritorna True\n",
    "    return (similarities >= SIMILARITY_THRESHOLD).any().item()\n",
    "\n",
    "# Processa ogni riga e determina se il match semantico supera la soglia\n",
    "results = [check_similar_option_batch(idx, row) for idx, row in tqdm(df.iterrows())]\n",
    "df['is_similar_in_path'] = results\n",
    "\n",
    "# Calcola e stampa il contatore finale\n",
    "counter = sum(results)\n",
    "print(f\"Numero di righe in cui almeno un segmento del path risulta simile (>= 80%) all'opzione corretta: {counter}\")\n",
    "\n",
    "# Visualizza il DataFrame aggiornato\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
