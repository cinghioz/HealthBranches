{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "# from together import Together\n",
    "from alive_progress import alive_bar\n",
    "from collections import Counter\n",
    "\n",
    "from prompt import *\n",
    "from utils import extract_option\n",
    "\n",
    "PATH = \"/home/cc/PHD/HealthBranches/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(\"/home/cc/PHD/HealthBranches/results/results_QUIZ_bench_deepseek-r1_8b.csv\")\n",
    "cnt = 0\n",
    "\n",
    "for index, row in ds.iterrows():\n",
    "    if extract_option(row['zero_shot']) not in ['A', 'B', 'C', 'D', 'E']:\n",
    "        cnt +=1\n",
    "        print(row['zero_shot'])\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/cc/PHD/HealthBranches/results/results_QUIZ_bench_qwen2.5_7b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compute path length as the number of '->' in each string\n",
    "df['path_len'] = df['path'].str.count(r'->')\n",
    "\n",
    "# 3. Group by that new column\n",
    "grouped = df.groupby('path_len')\n",
    "\n",
    "# 4a. If you just want to see group sizes:\n",
    "print(\"Rows per path-length:\")\n",
    "print(grouped.size().sort_index())\n",
    "\n",
    "# 4b. If you want to iterate through each group:\n",
    "for length, group in grouped:\n",
    "    print(f\"\\n=== Path length = {length} (i.e. {length} '->' separators) ===\")\n",
    "    print(group[['path']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compute path length (number of '->')\n",
    "df['path_len'] = df['path'].str.count(r'->')\n",
    "\n",
    "# 3. Apply extract_option to 'answer' and compare to 'real'\n",
    "#    (Assuming extract_option is already defined or imported)\n",
    "df['pred'] = df['zero_shot'].apply(extract_option)\n",
    "df['correct'] = df['pred'] == df['real']\n",
    "\n",
    "# 4. Group by path length and count matches & totals\n",
    "agg = (\n",
    "    df\n",
    "    .groupby('path_len')\n",
    "    .agg(\n",
    "        total_rows=('correct','size'),\n",
    "        correct_count=('correct','sum')\n",
    "    )\n",
    "    .sort_index()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "total_rows_all = len(df)\n",
    "agg['accuracy'] = agg['correct_count'] / total_rows_all\n",
    "\n",
    "# 7) Plot bar chart of weighted accuracies\n",
    "labels = [str(length) for length in agg.index]\n",
    "weighted_accuracies = agg['accuracy']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.bar(labels, weighted_accuracies)\n",
    "plt.xlabel('Path Length (number of \"->\" separators)')\n",
    "plt.ylabel('Weighted Accuracy\\n(corrects ÷ total rows)')\n",
    "plt.title('Weighted Accuracy by Path Length')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Annotate bars with percentages\n",
    "for bar, val in zip(bars, weighted_accuracies):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        val + 0.005,\n",
    "        f\"{val:.0%}\",\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/cc/PHD/HealthBranches/questions_pro/final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Carica il CSV con le domande da escludere\n",
    "df_blocklist = pd.read_csv(\"/home/cc/PHD/HealthBranches/questions_to_remove.csv\")\n",
    "\n",
    "# 2) Carica il CSV originale che vuoi filtrare\n",
    "df_orig = pd.read_csv(\"/home/cc/PHD/HealthBranches/questions_pro/dataset_updated_V2path.csv\")\n",
    "\n",
    "# 3) Filtra: tieni solo le righe il cui 'question' NON è nella blocklist\n",
    "df_filtrato = df_orig[~df_orig['question'].isin(df_blocklist['question'])]\n",
    "\n",
    "# 4) Scrivi il risultato su un nuovo CSV\n",
    "df_filtrato.to_csv('tutte_le_domande_filtrate.csv', index=False)\n",
    "print(len(df_filtrato))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_options(opt_str):\n",
    "    \"\"\"\n",
    "    Ritorna True se opt_str può essere convertito in lista di lunghezza 5,\n",
    "    altrimenti False (anche in caso di eccezione di parsing).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Normalizza le virgolette e tenta l'ast.literal_eval\n",
    "        opts = ast.literal_eval(\n",
    "            opt_str\n",
    "            .replace(\"['\", '[\"')\n",
    "            .replace(\"']\", '\"]')\n",
    "            .replace(\"', '\", '\", \"')\n",
    "        )\n",
    "        # Controlla che sia lista di lunghezza 5\n",
    "        return isinstance(opts, list) and len(opts) == 5\n",
    "    except (ValueError, SyntaxError):\n",
    "        return False\n",
    "\n",
    "# Applichiamo il filtro sul DataFrame originale\n",
    "mask = df['options'].apply(is_valid_options)\n",
    "\n",
    "# df filtrato: mantengo solo le righe valide\n",
    "df = df.loc[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/cc/PHD/HealthBranches/questions_pro/dataset_updated_V2path.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for c in df['correct_option'].values:\n",
    "    if c not in [\"A\", \"B\", \"C\", \"D\", \"E\"]:\n",
    "        print(i)\n",
    "        print(df.loc[i]['correct_option'])\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{PATH}results/results_quiz_Llama-3.3-70B-Instruct-Turbo-Free.csv\")\n",
    "df[\"zero_shot_new\"] = df[\"zero_shot\"].apply(extract_option)\n",
    "\n",
    "big_filtered = df[df[\"zero_shot_new\"].str.upper() != df[\"real\"].str.upper()]\n",
    "len(big_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = pd.read_csv(f\"{PATH}results/results_quiz_mistral.csv\")\n",
    "small_df = small_df[small_df[\"question\"].isin(big_filtered[\"question\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df[\"zero_shot_new\"] = small_df[\"zero_shot\"].apply(extract_option)\n",
    "small_filtered = small_df[small_df[\"zero_shot_new\"].str.upper() != small_df[\"real\"].str.upper()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory contenente i file CSV\n",
    "csv_directory = \"/home/cc/PHD/HealthBranches/quiz-ultimate-dataset\"\n",
    "\n",
    "# Leggere tutti i CSV\n",
    "csv_files = [os.path.join(csv_directory, f) for f in os.listdir(csv_directory) if f.endswith(\".csv\")]\n",
    "questions = []\n",
    "\n",
    "print(csv_files)\n",
    "\n",
    "# Elaborazione di ogni CSV\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Rimuove la colonna \"zero_shot_rag\" se esiste\n",
    "    if \"zero_shot_rag\" in df.columns:\n",
    "        df = df.drop(columns=[\"zero_shot_rag\"])\n",
    "\n",
    "    # Applica la funzione di estrazione su zero_shot\n",
    "    df[\"zero_shot\"] = df[\"zero_shot\"].apply(extract_option)\n",
    "\n",
    "    # Filtra le righe in cui zero_shot è diverso da real\n",
    "    df_filtered = df[df[\"zero_shot\"] != df[\"real\"]].copy()\n",
    "\n",
    "    questions.extend(df_filtered['question'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta le occorrenze\n",
    "conteggio = Counter(questions)\n",
    "\n",
    "# Ordina in ordine decrescente\n",
    "dizionario_ordinato = dict(sorted(conteggio.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "filtered_dict = {k: v for k, v in dizionario_ordinato.items() if v >= 6}\n",
    "\n",
    "print(len(filtered_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_to_check = pd.read_csv(\"/home/cc/PHD/HealthBranches/questions_to_check.csv\")\n",
    "\n",
    "# Trova le domande che sono sia nel dizionario che nel DataFrame\n",
    "matching_questions = [q for q in filtered_dict.keys() if q in questions_to_check[\"question\"].values]\n",
    "print(len(matching_questions))\n",
    "\n",
    "print(\"Domande trovate nel DataFrame:\", len(matching_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il CSV (sostituisci 'file.csv' con il tuo file)\n",
    "df = pd.read_csv(\"/home/cc/PHD/HealthBranches/results/results_checker_70B.csv\")\n",
    "\n",
    "# Conta le occorrenze di ogni valore nella colonna \"check\"\n",
    "conteggio = df[\"check\"].value_counts().sort_index()\n",
    "\n",
    "# Stampa il risultato\n",
    "print(conteggio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Se la GPU è disponibile, usa 'cuda', altrimenti 'cpu'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Esecuzione su: {device}\")\n",
    "\n",
    "# Carica il modello sulla GPU se disponibile\n",
    "model = SentenceTransformer('all-mpnet-base-v2', device=device)\n",
    "\n",
    "# Sostituisci 'data.csv' con il percorso del tuo file CSV.\n",
    "df = pd.read_csv('/home/cc/PHD/HealthBranches/questions_pro/dataset_updated_V2path.csv')\n",
    "\n",
    "# Definisce la soglia di similarità (80%)\n",
    "SIMILARITY_THRESHOLD = 0.9\n",
    "\n",
    "# Pre-elabora il DataFrame:\n",
    "# 1. Dividi il campo 'path' in una lista di segmenti\n",
    "df['path_segments'] = df['path'].apply(lambda x: [seg.strip() for seg in x.split(\"->\")])\n",
    "# 2. Estrai il testo dell'opzione corretta\n",
    "def extract_correct_option(row):\n",
    "    try:\n",
    "        options_list = ast.literal_eval(row['options'].replace(\"['\", '[\"').replace(\"']\", '\"]').replace(\"', '\", '\", \"'))\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        # Se il parsing fallisce, restituisce una stringa vuota\n",
    "        return \"\"\n",
    "    correct_letter = row['correct_option'].strip().upper()\n",
    "    index = ord(correct_letter) - ord('A')\n",
    "    if index < 0 or index >= len(options_list):\n",
    "        return \"\"\n",
    "    return options_list[index]\n",
    "\n",
    "df['correct_option_text'] = df.apply(extract_correct_option, axis=1)\n",
    "\n",
    "# Elabora in batch gli embedding delle opzioni corrette\n",
    "correct_texts = df['correct_option_text'].tolist()\n",
    "correct_embeddings = model.encode(correct_texts, device=device, convert_to_tensor=True)\n",
    "\n",
    "# Funzione per verificare in una riga se almeno un segmento del path è semanticamente simile all'opzione corretta\n",
    "def check_similar_option_batch(idx, row):\n",
    "    segments = row['path_segments']\n",
    "    # Se non ci sono segmenti, ritorna False\n",
    "    if not segments:\n",
    "        return False\n",
    "    # Calcola in batch gli embedding dei segmenti (convert_to_tensor=True per operare su GPU)\n",
    "    segments_embeddings = model.encode(segments, device=device, convert_to_tensor=True)\n",
    "    # Recupera l'embedding dell'opzione corretta per la riga corrente\n",
    "    correct_emb = correct_embeddings[idx]\n",
    "    # Normalizza gli embedding per applicare correttamente il calcolo della similarità coseno\n",
    "    correct_norm = correct_emb / correct_emb.norm()\n",
    "    segments_norm = segments_embeddings / segments_embeddings.norm(dim=1, keepdim=True)\n",
    "    # Calcola la similarità coseno tra l'opzione e ogni segmento\n",
    "    similarities = torch.matmul(segments_norm, correct_norm)\n",
    "    # Se almeno una similarità supera la soglia, ritorna True\n",
    "    return (similarities >= SIMILARITY_THRESHOLD).any().item()\n",
    "\n",
    "# Processa ogni riga e determina se il match semantico supera la soglia\n",
    "results = [check_similar_option_batch(idx, row) for idx, row in tqdm(df.iterrows())]\n",
    "df['is_similar_in_path'] = results\n",
    "\n",
    "# Calcola e stampa il contatore finale\n",
    "counter = sum(results)\n",
    "print(f\"Numero di righe in cui almeno un segmento del path risulta simile (>= 80%) all'opzione corretta: {counter}\")\n",
    "\n",
    "# Visualizza il DataFrame aggiornato\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
