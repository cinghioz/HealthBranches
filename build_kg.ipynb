{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sys\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_file, path_column='path', question_column='question'):\n",
    "    \"\"\"\n",
    "    Legge il CSV e ritorna una lista di path e una lista di domande.\n",
    "    I path sono formattati come stringhe \"decision -> decision -> ...\".\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # Estrae i path e li suddivide in liste di decisioni\n",
    "    paths = df[path_column].dropna().tolist()\n",
    "    paths = [[d.strip() for d in p.split('->')] for p in paths]\n",
    "    \n",
    "    # Estrae le domande se presenti\n",
    "    questions = []\n",
    "    if question_column in df.columns:\n",
    "        questions = df[question_column].dropna().tolist()\n",
    "        \n",
    "    return paths, questions\n",
    "\n",
    "def get_unique_decisions(paths):\n",
    "    \"\"\"\n",
    "    Estrae tutte le decisioni uniche dai path.\n",
    "    \"\"\"\n",
    "    decisions = set()\n",
    "    for path in paths:\n",
    "        decisions.update(path)\n",
    "    return list(decisions)\n",
    "\n",
    "def cluster_decisions(decisions, model, similarity_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Crea le embedding delle decisioni e le raggruppa in cluster usando AgglomerativeClustering.\n",
    "    La soglia di similarità (coseno) viene usata per definire la distanza (1 - similarità).\n",
    "    \"\"\"\n",
    "    # Ottieni le embedding per ciascuna decisione\n",
    "    embeddings = model.encode(decisions, convert_to_numpy=True)\n",
    "    # Calcola la distanza: 1 - cos_sim\n",
    "    distance_threshold = 1 - similarity_threshold\n",
    "\n",
    "    # Agglomerative clustering con distanza basata su similarità coseno\n",
    "    clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=distance_threshold, metric='cosine', linkage='average')\n",
    "    labels = clustering.fit_predict(embeddings)\n",
    "    \n",
    "    # Raggruppa le decisioni per cluster\n",
    "    clusters = {}\n",
    "    for decision, label in zip(decisions, labels):\n",
    "        clusters.setdefault(label, []).append(decision)\n",
    "    return clusters, labels, embeddings\n",
    "\n",
    "def get_cluster_representatives(clusters, model):\n",
    "    \"\"\"\n",
    "    Per ogni cluster, seleziona una decisione rappresentativa (ad esempio, quella più vicina al centroide).\n",
    "    \"\"\"\n",
    "    representatives = {}\n",
    "    for label, items in clusters.items():\n",
    "        # Ottieni le embedding per le decisioni del cluster\n",
    "        item_embeddings = model.encode(items, convert_to_numpy=True)\n",
    "        # Calcola il centroide del cluster\n",
    "        centroid = np.mean(item_embeddings, axis=0)\n",
    "        # Seleziona la decisione più vicina al centroide\n",
    "        distances = np.linalg.norm(item_embeddings - centroid, axis=1)\n",
    "        rep = items[np.argmin(distances)]\n",
    "        representatives[label] = rep\n",
    "    return representatives\n",
    "\n",
    "def build_path_graph(paths, decision_to_cluster):\n",
    "    \"\"\"\n",
    "    Crea un grafo diretto basato sui path originali.\n",
    "    Per ogni path, viene mappata la sequenza di decisioni nel rispettivo rappresentante (cluster)\n",
    "    e vengono aggiunti gli archi con peso incrementale.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    for path in paths:\n",
    "        # Mappa ogni decisione al suo rappresentante (cluster)\n",
    "        aggregated_path = [decision_to_cluster[d] for d in path]\n",
    "        # Aggiungi nodi e archi (incrementando il peso se l'arco è già presente)\n",
    "        for i in range(len(aggregated_path)-1):\n",
    "            u = aggregated_path[i]\n",
    "            v = aggregated_path[i+1]\n",
    "            if G.has_edge(u, v):\n",
    "                G[u][v]['weight'] += 1\n",
    "            else:\n",
    "                G.add_edge(u, v, weight=1)\n",
    "    return G\n",
    "\n",
    "def build_knn_graph(cluster_embeddings, representatives, k=5):\n",
    "    \"\"\"\n",
    "    Costruisce un grafo non diretto (KNN graph) usando le embedding dei rappresentanti dei cluster.\n",
    "    Vengono collegati ciascun nodo ai suoi k vicini (saltando il nodo stesso).\n",
    "    \"\"\"\n",
    "    # Prepara la lista di rappresentanti e le relative embedding\n",
    "    rep_texts = list(representatives.values())\n",
    "    rep_embeddings = []\n",
    "    # Mappa da etichetta a rappresentante\n",
    "    rep_label = {}\n",
    "    for label, rep in representatives.items():\n",
    "        rep_label[rep] = label\n",
    "        rep_embeddings.append(cluster_embeddings[label])\n",
    "    rep_embeddings = np.vstack(rep_embeddings)\n",
    "    \n",
    "    # Trova i k vicini usando NearestNeighbors (metric 'cosine')\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1, metric='cosine').fit(rep_embeddings)\n",
    "    distances, indices = nbrs.kneighbors(rep_embeddings)\n",
    "    \n",
    "    G_knn = nx.Graph()\n",
    "    for i, (dists, idxs) in enumerate(zip(distances, indices)):\n",
    "        for j, idx in enumerate(idxs[1:]):  # ignora il nodo stesso\n",
    "            u = rep_texts[i]\n",
    "            v = rep_texts[idx]\n",
    "            # La similarità coseno = 1 - distanza\n",
    "            weight = 1 - dists[j]\n",
    "            G_knn.add_edge(u, v, weight=weight)\n",
    "    return G_knn\n",
    "\n",
    "def retrieve_similar_nodes(questions, representatives, cluster_embeddings, model, k=3):\n",
    "    \"\"\"\n",
    "    Per ciascuna domanda, calcola l'embedding e ne ricava i k nodi più simili basandosi sulla similarità coseno.\n",
    "    Restituisce un dizionario: domanda -> lista di (nodo, similarità).\n",
    "    \"\"\"\n",
    "    # Prepara lista dei rappresentanti e delle loro embedding\n",
    "    rep_texts = list(representatives.values())\n",
    "    rep_labels = list(representatives.keys())\n",
    "    rep_emb_list = [cluster_embeddings[label] for label in rep_labels]\n",
    "    rep_embs = np.vstack(rep_emb_list)\n",
    "    \n",
    "    results = {}\n",
    "    for question in questions:\n",
    "        q_emb = model.encode([question], convert_to_numpy=True)\n",
    "        sims = cosine_similarity(q_emb, rep_embs)[0]\n",
    "        # Ottieni gli indici dei k nodi più simili ordinati per similarità decrescente\n",
    "        top_indices = sims.argsort()[-k:][::-1]\n",
    "        similar_nodes = [(rep_texts[i], sims[i]) for i in top_indices]\n",
    "        results[question] = similar_nodes\n",
    "    return results\n",
    "\n",
    "def check_edges_between_nodes(nodes, graph):\n",
    "    \"\"\"\n",
    "    Dati una lista di nodi, controlla se esistono edge (in una direzione o nell'altra) nel grafo.\n",
    "    Restituisce una lista di tuple (u, v, data) per ogni edge trovato.\n",
    "    \"\"\"\n",
    "    edges_found = []\n",
    "    # Controlla ogni coppia di nodi\n",
    "    for u, v in itertools.combinations(nodes, 2):\n",
    "        # Per grafi misti (diretto e indiretto) controlliamo in entrambe le direzioni\n",
    "        if graph.has_edge(u, v):\n",
    "            edges_found.append((u, v, graph.get_edge_data(u, v)))\n",
    "        if graph.has_edge(v, u):\n",
    "            edges_found.append((v, u, graph.get_edge_data(v, u)))\n",
    "    return edges_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Carica i path dal file CSV\n",
    "paths, questions = load_data(\"/home/cc/PHD/HealthBranches/questions_pro/ultimate_questions_v3_full_balanced.csv\")\n",
    "\n",
    "# Estrai tutte le decisioni uniche\n",
    "unique_decisions = get_unique_decisions(paths)\n",
    "\n",
    "# Inizializza il modello di embedding\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# Esegui il clustering delle decisioni per aggregare quelle simili\n",
    "clusters, labels, embeddings = cluster_decisions(unique_decisions, model, similarity_threshold=0.7)\n",
    "\n",
    "# Seleziona un rappresentante per ogni cluster\n",
    "representatives = get_cluster_representatives(clusters, model)\n",
    "\n",
    "# Crea una mappa: decisione originale -> rappresentante del cluster\n",
    "decision_to_cluster = {}\n",
    "for decision, label in zip(unique_decisions, labels):\n",
    "    decision_to_cluster[decision] = representatives[label]\n",
    "\n",
    "# Costruisci il grafo basato sui path (grafo diretto) mantenendo gli edge originali aggregati\n",
    "path_graph = build_path_graph(paths, decision_to_cluster)\n",
    "print(\"Nodi del Path Graph:\")\n",
    "print(path_graph.number_of_nodes())\n",
    "print(\"\\nArchi del Path Graph:\")\n",
    "print(path_graph.number_of_edges())\n",
    "\n",
    "# Prepara le embedding dei rappresentanti (una per ogni cluster)\n",
    "cluster_embeddings = {}\n",
    "for label, items in clusters.items():\n",
    "    # Utilizziamo la embedding del rappresentante come embedding del cluster\n",
    "    idx = unique_decisions.index(representatives[label])\n",
    "    cluster_embeddings[label] = embeddings[idx]\n",
    "\n",
    "# Costruisci il grafo KNN usando le embedding dei rappresentanti\n",
    "knn_graph = build_knn_graph(cluster_embeddings, representatives, k=5)\n",
    "print(\"\\nNodi del KNN Graph:\")\n",
    "print(knn_graph.number_of_nodes())\n",
    "print(\"\\nArchi del KNN Graph:\")\n",
    "print(knn_graph.number_of_edges())\n",
    "\n",
    "# Unisci i due grafi: manteniamo sia gli edge derivanti dai path originali che quelli dal KNN graph\n",
    "final_graph = nx.compose(path_graph, knn_graph)\n",
    "print(\"\\nNodi del Grafo Finale:\")\n",
    "print(final_graph.number_of_nodes())\n",
    "print(\"\\nArchi del Grafo Finale:\")\n",
    "print(final_graph.number_of_edges())\n",
    "# (Opzionale) Salva o visualizza il grafo finale, ad esempio:\n",
    "# nx.write_gpickle(final_graph, \"final_graph.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se sono presenti domande, effettua il retrieval dei nodi più simili per ciascuna\n",
    "if questions:\n",
    "    retrieval = retrieve_similar_nodes(questions, representatives, cluster_embeddings, model, k=3)\n",
    "    print(\"\\nRisultati del retrieval per ogni domanda:\")\n",
    "    for question, similar_nodes in retrieval.items():\n",
    "        print(f\"\\nDomanda: {question}\")\n",
    "        nodes_retrieved = [node for node, sim in similar_nodes]\n",
    "        for node, sim in similar_nodes:\n",
    "            print(f\"  Nodo: {node} - Similarità: {sim:.4f}\")\n",
    "        edges_between = check_edges_between_nodes(nodes_retrieved, final_graph)\n",
    "        if edges_between:\n",
    "            print(\"  Gli edge che collegano i nodi sono:\")\n",
    "            for u, v, data in edges_between:\n",
    "                print(f\"    {u} -> {v} con attributi {data}\")\n",
    "        else:\n",
    "            print(\"  Nessun edge diretto trovato tra i nodi recuperati.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
